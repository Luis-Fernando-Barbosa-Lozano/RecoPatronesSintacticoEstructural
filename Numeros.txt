200
1
4
2

import keyword
import re

# Obtener palabras reservadas y constantes de Python
palabras_reservadas = keyword.kwlist
constantes = {'None', 'True', 'False'}

# Función para procesar el archivo y categorizar los elementos
def analizar_codigo(archivo_entrada, archivo_salida):
    # Leer el archivo de entrada
    with open(archivo_entrada, 'r') as archivo:
        codigo = archivo.read()

    # Definir patrones para diferentes tipos de tokens
    patrones = {
        'TokenID': re.compile(r'\b[a-zA-Z_]\w*\b'),  # Identificadores
        'TokenNumero': re.compile(r'\b\d+(\.\d+)?\b'),  # Números enteros y flotantes
        'TokenOperador': re.compile(r'[+\-*/%<>=!]+'),  # Operadores
        'TokenString': re.compile(r'\".*?\"|\'[^\']*\'', re.DOTALL),  # Cadenas de texto
        'TokenEspacioBlanco': re.compile(r'\s+'),  # Espacios en blanco
        'TokenComparacion': re.compile(r'==|!=|<=|>=|<|>'),  # Comparaciones
        'TokenPuntuacion': re.compile(r'[.,;]'),  # Puntuación
        'TokenConstante': re.compile(r'\bNone\b|\bTrue\b|\bFalse\b'),  # Constantes
    }

    # Encontrar y categorizar todos los tokens en el código
    resultados = {key: [] for key in patrones}
    for token_type, patron in patrones.items():
        resultados[token_type] = patron.findall(codigo)

    # Encontrar identificadores y palabras reservadas
    palabras = resultados['TokenID']
    identificadores = [p for p in palabras if p not in palabras_reservadas and p not in constantes]
    palabras_reservadas_encontradas = [p for p in palabras if p in palabras_reservadas]

    # Crear el formato de salida
    salida = [
        f"TokenID: {', '.join(identificadores)}",
        f"TokenNumero: {', '.join(set(resultados['TokenNumero']))}",
        f"TokenOperador: {', '.join(set(resultados['TokenOperador']))}",
        f"TokenString: {', '.join(set(resultados['TokenString']))}",
        f"TokenEspacioBlanco: {', '.join(set(repr(x) for x in resultados['TokenEspacioBlanco']))}",
        f"TokenComparacion: {', '.join(set(resultados['TokenComparacion']))}",
        f"TokenPuntuacion: {', '.join(set(resultados['TokenPuntuacion']))}",
        f"TokenConstante: {', '.join(set(resultados['TokenConstante']))}",
        f"TokenPalabraReservada: {', '.join(palabras_reservadas_encontradas)}"
    ]

    # Guardar el resultado en el archivo de salida
    with open(archivo_salida, 'w') as archivo:
        archivo.write("\n".join(salida))

    # Mostrar el contenido del archivo de salida
    with open(archivo_salida, 'r') as archivo:
        print(archivo.read())

# Archivo de entrada con el código
archivo_entrada = "codigo_texto.txt"

# Archivo de salida donde se guardarán los tokens categorizados
archivo_salida = "tokens_categorizados.txt"

# Llamada a la función para analizar el código
analizar_codigo(archivo_entrada, archivo_salida)
